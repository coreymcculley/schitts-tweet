# <<< Schitts Tweets - Data Bootcamp Project-3 >>>

![proj_logo.png](IgorP/Twitter_Code.png)


## Team

Christy Patrick, Igor Pavlunin, Corey McCulley


## Background

The agenda of this project is Twitter sentiment analysis and toxicity classification. In order to satisfy requirements, two NLP models were implemented. The sentiment analysis model identifies whenever a tweet is positive, neutral or negative by returning analysis scores from 0 to 1. Score 0 identifies absolute negative sentiment and Score 1 absolute positive sentiment accordingly. The toxicity model returns prediction scores for 6 categories - hate speech, Insulting, Threating, Obscenity, Toxicity and Severe Toxicity within a range of 0 - 100%. Higher score corresponding to predomination of a given category.


## Brief introduction to NLP

Natural Language Processing (NLP) discipline of computer science, artificial intelligence and linguistics that is concerned with the creation of computational models that process and understand natural language. These include: making the computer understand the semantic grouping of words (e.g. cat and dog are semantically more similar than cat and spoon), text to speech, language translation and many more.


## Models Construction

Model1 - Sequence NLP model that can perform sentiment analysis to categorize tweets as Positive, Negative or Neutral with a gradation pattern depending on score value. Dataset used to train and test model contains 1.6B tweets extracted from Twitter API. Notebooks for building and testing the model are provided within the GitHub folder. Model accuracy score is 84%. The model consist of the following layers:
* Preprocessing text input (this is standalone text cleaning step outside of the model layers).
* Embedding Layer - responsible for converting the tokens into their vector representation that is generated by Word2Vec model. We're using the predefined layer from TensorFlow in out model.
* Bidirectional wrapper for RNNs. It means the context are carried from both left to right and right to left in the wrapped RNN layer.
* Long Short-Term Memory, itâ€™s a variant of RNN which has memory state cell to learn the context of words which are at further along the text to carry contextual meaning rather than just neighboring words as in case of RNN.
* Conv1D layer - creates a convolution kernel that is convolved with the layer input over a single dimension to produce a tensor of outputs.
* GlobalMaxPool1D layer - creates a convolution kernel that is convolved with the layer input over a single dimension to produce a tensor of outputs.
* Dense layer - adds a fully connected layer in the model. The argument passed specifies the number of nodes in that layer. The last dense layer has the activation "Sigmoid", which is used to transform the input to a number between 0 and 1. Sigmoid activations are generally used when we have 2 categories to output.


Model2 - Bidirectional NLP with convolution model that can perform vulgarity analysis and categorize tweets as Toxic, Severe Toxic, Obscene, Threat, Insult or Hate Speech. The output yields a probability score for the tweet to fit into each category. The dataset was obtained from Kaggle and contains 160K tweets. Notebooks for building and testing the model are provided within the Github folder. The model consists of the following layers:

* Preprocessing text input (this is standalone text cleaning step outside of the model layers).
* Embedding Layer - responsible for converting the tokens into their vector representation .
* Spatial Dropout - Drops certain features of the data across the entire set to prevent overfitting when training.
* Bidirectional hidden layer analysis performing L and R analysis across the tweet text.
* Convolution hidden layer which takes the words and groups them into small chains to aid in the relationship matching.
* Global Pooling - Pools the convolutional layer into a tensor of outputs.
* Concatenation - Combines the 2 global pooling average and max outputs.
* Dense Layer - adds a fully connected layer to the model. The argument passed specifies the number of nodes in this layer.


## Practical Application and Visualization

As soon as both models are built, trained and tested, it's time to visualize their practical application and final results. In order of doing that we've built a Web application using Flask, Twitter API, Tableau, HTML and JS. Current functionality includes (but not limited to) scrapping Twitter by user name and displaying a table of the latest 10 tweets. Text entry field to type in or paste any tweet for analysis. Model prediction output provides numerical scores both for sentiment and toxicity categories. Another type of available analysis is a Tableau dashboard displaying sentiment and toxicity analysis for a number of Tweeter users.
Sentiment and toxicity analysis allows organizations to identify public relations towards certain words or topics. Influencer can gain assurance that their tweets are positive. Social media marketing analysis and gain insights on social media mentions.


